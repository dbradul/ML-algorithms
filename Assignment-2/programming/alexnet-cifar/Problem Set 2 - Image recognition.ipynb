{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem Set 2 - Image recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ROssOKvTeX3K",
        "e-K-vXgWLVae",
        "5HIZnC3-eX31"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5Bbpur1IeX25",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional neural networks"
      ]
    },
    {
      "metadata": {
        "id": "PDXC0GobeX2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Olexander Chepurnoi, Yaroslava Lochman"
      ]
    },
    {
      "metadata": {
        "id": "-_ZsSduqeX3B",
        "colab_type": "code",
        "outputId": "49e0b057-d0c3-4d20-b3eb-8c4e5e064a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "cell_type": "code",
      "source": [
        "_colab = True\n",
        "if _colab:\n",
        "  print('Using Google Colab')\n",
        "  \n",
        "  # !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive \n",
        "  from google.colab import auth \n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  \n",
        "  # !pip install tensorboardcolab\n",
        "  from tensorboardcolab import *\n",
        "  \n",
        "import pickle\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "print('Keras version using:', keras.__version__)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Google Colab\n",
            "Keras version using: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QyyG9EK8m_KF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ROssOKvTeX3K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading images"
      ]
    },
    {
      "metadata": {
        "id": "A1F9GLJ6eX3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if _colab:\n",
        "  from keras.datasets import cifar10\n",
        "  (train_images, train_labels), (cv_images, cv_labels) = cifar10.load_data()\n",
        "else:\n",
        "  train_images, train_labels = pickle.load(open('data/train_set_all.pkl', 'rb'))\n",
        "  cv_images, cv_labels = pickle.load(open('data/test_set_all.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2z38okReX3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "40b5e0b3-82c4-4fa5-c2dc-a6b4a4ece58f"
      },
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzdIcxzEeX3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "ed88564c-fca1-4a32-d4f6-fb73e92fe972"
      },
      "cell_type": "code",
      "source": [
        "print(cv_images.shape)\n",
        "print(len(cv_labels))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8l5N_PjReX3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4ddf983c-ac29-4d6a-be09-67ec994f58c4"
      },
      "cell_type": "code",
      "source": [
        "print(train_labels[0:10])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6]\n",
            " [9]\n",
            " [9]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [7]\n",
            " [8]\n",
            " [3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j1akWgnkeX3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_image(np_array):\n",
        "    %matplotlib inline\n",
        "    plt.figure()\n",
        "    plt.imshow(np_array)\n",
        "    \n",
        "def show_example(data_set, labels, example_index):\n",
        "    show_image(data_set[example_index])\n",
        "    print('Label: ', labels[example_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hGfpwjuveX3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f8aabb16-50fc-41fe-99de-4701cf4d9d3a"
      },
      "cell_type": "code",
      "source": [
        "show_example(train_images, train_labels, example_index = 0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  [6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnWuUXVWVqL/zrDr1rkq9kkoghoQl\n70eUCyiX0EiLitBepBleRC7Qig5w2Cq3xcYXYA8VRBwiQ8FWXnZ7kaavgjBshRa5SN/mIaC8VgiE\nkHcqqapUnTqnzvv+2GdjKnvNneKQnOK65zcGg+y5au29zjp77rXPnGvOGavVaiiK8udNfL4HoCjK\nvkcVXVEigCq6okQAVXRFiQCq6IoSAVTRFSUCJBvtaIy5DjgWqAGfstY+Jv3tO09cNcuHd9vNN/OR\n888HYGJiTLxGS7zqlPelZZfgfgvaxLaBvvZZx3/7tZv59ue9cfT3dIj90omUU55syYh9SMhTOzY+\nMev4Y1+8npuu+iQAxbL82Xp7usW2eKXklBcKBbHPzMzMrOOPX/l9vv+ljwPQmmkV+1WoiG25fNYp\n7+7pEvtQm32+//F3N3DL1RcDUCwUxW4J3N8LQCKRcMo7O+Tvub199v1x2se+wi9u+goAqZQ8H/mQ\nMdZiIWtp3H2P7P6Zz7r4S9x5w5UAlGsx8XQXX/V9sbGhFd0YcyKwwlp7HHAh8J3X03/Zsrc0ctm9\nzvCSN8c4Bkf2n+8hADC4eOl8DwGA/oVvjvnoGRyZ7yEA0Df0xsfR6Kv7ycDPAKy1zwO9xpiQR7ai\nKPNJo4o+DIzucjxalymK8iYk1sgWWGPMTcC91tqf148fBi6w1q52/f3LL6+tvVle1xXlzxjxN3qj\nxrhNzF7BFwGbpT/2DW8+D//2Qd554ipgfo1xX//xg1z2YW8c82mM+8L37+arHz8dmF9j3Jd+9Euu\nvOBUYH6NcZde9wu++enTgPk1xn34Cz/gx1/9KDC/xriLrryRG790EbBHY5x8KXkUofwK+CCAMeZo\nYJO1dqrBcymKso9paEW31j5ijHnCGPMIUAUuDvv7Z597VpRNbN8u9usTHqKxBfLTtb/SKbbFMoNB\nWd67/nRVfrPIVtyrbC2WFvvkZuSnfC4fXGU3r30BgFLF/RYDsD0hP81bk+4xlsvy+RKOFWV888sA\ntLS0iP1yM9NiW7nq/tyxmQVin7hj8c1uXw9AKeSNJJOU74OssMqOVcpin7a29oDsleceByAWl98e\nYsIbHwBxeS3NzbjfwsqloHxtfRyJpPy9hNGwH91ae1mjfRVFaS66M05RIoAquqJEAFV0RYkAquiK\nEgFU0RUlAjRsdX89ZJJBt9BrshBvwf6CG23pkLxxZHCgTx6Hw33iy2Ix2XWVL8w45TMl2fVTCzlf\nOhPcaPOaLGTDTK0qX6+7z71RqFySz5dOBcfR1++5wSrynhgSaflLKxTdc1Uqy/PR5jhfIuF998l2\neVNSa8g4yjG3CzBek92NZcfGsnJ9LQzxbNLRLm/Syk7nxLZS2e1eizuu5d9OU5M75YGEoCu6okQA\nVXRFiQCq6IoSAVTRFSUCqKIrSgRoitW9NRYMJPBlnZ3yEA4c6XXKF2TcIYgAqarb6guQHQsGOmTH\ndgBQqcrPvHzOHQgRl2Na6AoJe006rMWd7Z5sYqccBJgM+bb6Ot2W36lJOQCl6AhOqdRleSHgAqAm\nhz3T0R70bACUinmxT7wS/GDxutk/FRJcUxFCcwGSgpm8UJD7pFPBLzRRvy3iVTkYppAdF9sQAqIA\nWoTbuFwNegZiMU+2c1r2vIShK7qiRABVdEWJAKroihIBVNEVJQKooitKBFBFV5QI0BT3Wm9L8DK+\nLBPiPukWAhoGuuQcXZWqHI3havHdMImk7LKT8n4VqiHunRBfWNIRWOHLKgXZDVVLyM/lbdsmnPJK\nSZ6PqVww4GLHhHeeXEXOedeRCcnoWnBfL4EcTBKPBV1QvizREpJ9dVp2pbal3GNMhqQ3n3Hk+avU\n3XH5kuxeqyKfcyIrj3Ei575/sg537h9We0mWZ0qNrc26oitKBFBFV5QIoIquKBFAFV1RIoAquqJE\nAFV0RYkADbnXjDGrgDsBv9bSH621n5T+fqAn6CLxZZ0p2a3V2upuiydkd0bGkY/Np1QOun7aWryI\npWpIRFat5nY1hRVErBRl11u1FmwrznjFCWshbq1aUg6Xmyq6o9QqFXl+c47yT76sHFIaampa/mwb\nx9zjSAkFMwG6ssG5f2Wz55YqbZFLduV3yvnY9utf7pQPDi4W+8Q6g/nYMp1eDr3C+A6xXzYrRwju\nnJLda9t3ul2pr6wPjuOFF7cCUAkp3hnGG/Gj/9Za+8E30F9RlCahr+6KEgHeyIp+sDHmbqAPuMJa\n++u9NCZFUfYysVrIlkAJY8wI8E7gp8Ay4DfAcmut8wfmK2tsbely80bGqSjKnhENTQ0p+u4YYx4F\nzrbWrnW1n3rUfrMu8ssnX+XUo/YDoDMlG3YW9btrnS/IyIazlpCk/rsb475w57N89axDgHBjXE6o\ntT1dkPc/d3W4UyoBxHYzxn31X1/gC//trQCMTUyK/eItsjEuKWz/DzXG7Van/Yf/voEL/8IzVpVD\njIKJmPzZJgvuMYYa49pm97nx189y0Sne91KKyS+djRnjwoo+zDaCfe5Hv+EbF5wEwESIMW4qxBi3\nY1Ie4+gcjXFrpmssb/fuzzBj3NrJkngTN/Qb3RhzjjHm0vq/h4EhYGMj51IUZd/T6G/0u4F/Nsac\nAaSBT0iv7QCLBoIrgC/rSsurYkebe3XYfUWcjfyGEnNEjfmyQl5+8saF1X5Bp1waqr1djrqa3Bl0\nGcXqkXDdXXJk2FRIwsZ1G91uqGxBXtHTjkV2yxZvHkbaQqLvUnKE3Ss73FF0hVpIQk9H9JpdtwWA\n7i73Wx3A8Qe/TWyb3OyOoqvl5Pujuz/4WtSd8WSFnDwf2ay8Xrak5EjLJcPuzzY4OBSQHbPyQAC2\nTsruujAaUnRr7RTw/oauqChK01H3mqJEAFV0RYkAquiKEgFU0RUlAqiiK0oEaEpyyL7OYESZL0sW\n3e4YgJaUe3htLe46YwCFvOyCKjnqZ5XqLqaeHnedNwBpU1GxIj8nS6WQxIUdwbpsvmzTqFxb66V1\nwagmn9Ept5tSKBsHwP6OGnbVupfxr044Uuy3eKFcV+5fnnjZKf+PNVvEPuVq0DMbq7vcknHZHTY1\nMSq25bLueezslN1dVBxu1Ir3Pba2yv3SQpQlQFtM7leuuL+c/ZYsCshW7D8AQOeYXJsvDF3RFSUC\nqKIrSgRQRVeUCKCKrigRQBVdUSJAU6zug30LRFl+TLZOx4UQxaxQygYgX5TNzMlY0DparstyIaWL\npKdhviSHcvb0ysEpxUrQklxJeOGTL2/YJPYbm5THKOWTS4SUcepqDZ6vq9VzQwwmZetu65jsGVjR\nNeyUb+6Tx7F1YltA1pn0PCuFnDzHT65eLbbFy+6w2FJ7SDmp7mAwyUShfp64rCrd3bIXqLMaUgJK\nyCtYKwZDlX3ZUkeA2FzQFV1RIoAquqJEAFV0RYkAquiKEgFU0RUlAqiiK0oEaIp7rbd/QJT1dsgl\nlOJxd0DAxOS42Kc0nZXPVwm6k+JJz61VRc5SWhOCazo65LxwJeS2518OuoWef9kruTNdkDOKtrbK\nGUxb0+4xZtpl109vIuiK7O3y3DdPrNkq9isX5dum0O12rw30yvMRI+jyGu7xZKWy7H7NFeXcddNC\nbrhiWXa/xhzu0tdkcpJgUvGQcl7xkFx5Sfc8lgtB96V/lprDNTsXdEVXlAigiq4oEUAVXVEigCq6\nokQAVXRFiQCq6IoSAebkXjPGHAr8HLjOWvtdY8wS4HY8q/9m4FxrrRzS5HKT1WWxkJI1Ei0h+bva\nkKN7ko7nWkdXjzeceEj+N8H11pKRSzJt3yJHf+W2B92DvmxZn+yGKoRU42kV3GjmgBGxT9xxwuX7\nexFc5YQ8x5Mh7s1kwp3XrjMtfy8Leg8IyMwyT3bAiv3EfmtffUxse2G1uxRgOinfprVa0DXry8pl\nWVXiQuQgQCotz2O16r6vXAU//bJgsVhja/Meexlj2oHrgQd2EV8J3GCtPQFYA1zQ0NUVRWkKc3k8\nFID3ArsGSq/CK7QIcA/wrr07LEVR9iZ7fHW31paBsjFmV3H7Lq/q24CF+2BsiqLsJWJSzvLdMcZ8\nBdhe/42+zVo7WJcvB26z1h4v9R3buqHWN7R4b4xXURQZcS9uo3vds8aYjLU2D4ww+7U+wF3fuXzW\n8Uf/4VZ+cPl53shK8t50adT5vNxnckZOPbS7Me7vfvAAV3/0ZKC5xrjnn/7PWcf/+/lJPnCQt7e7\ntzNkH3moMc5da/v1GOMuvfP3fPOsowHINGqMy7hjF8oJ2RiXbpmdauyzt9/Dted6Vbn3ujEuLS9s\nI0M9s44v+6fn+Po5BwNQrjRqjJPbJGNcMT97D/8X73iaq84+AoBkizyPn7/tEXmMYks49wNn1v99\nJvDLBs+jKEoT2OOKboxZCVwLLAVKxpgPAucAtxhjLgLWAbeGnSM/E0yC58tiJTkCCdyRRtPTweR5\nPsWS/Owqx4Ouq5mi94TP5uQVeFJoG1kiT1+tLJ9v//7gu4ovO2CRvJLmZuQoqZEDj3DK0zX5NWB8\nZ/B76ezx4qQyPcGEnq+xQ47IWjLsNtdMTMtRecveuiIg+y/He7KuXjn6rqv3ILFtfNQ9/+M75bJW\nKYcL0JfFa3LkYKkqJ+0UFm0AKiX3/e0KhvNlc/2pvTtzMcY9gWdl351TGrqioihNR3fGKUoEUEVX\nlAigiq4oEUAVXVEigCq6okSApiSHrMSC7gdfVqvIyfokV0KmVU4o2dEpu2M2jQZdeb7nb+2GUbFf\nMuUeR3qrvE9oZqt8vhWDQRfayAJPdvKqoKvJ56WNY2Jb50gwASdA/wJ3skaAbaPBBJArjvTcdD09\n8saMeFV2AaaFZIjbRt0bWACSrROibHRis9hv42Z541Qq5b4Perpkf1c+H/yefVktKa+JsZDkkNUQ\n11s85u4Xc2zeStZlDeaG1BVdUaKAKrqiRABVdEWJAKroihIBVNEVJQKooitKBGiKe62np0OUlZOy\ney2bdUde1Uqyy2LnlBydtO7VoDtp3avr69eSXTWZVvfzcPNaOYpuqFWOQx4Z2V+U9Sx6i9gvNRUS\nCiUkzFx8xDFyly1Bl9d+h9bj0cuye7CCHBE3Pe1uW9jmdv8BFCvBz9Xe6cXXx9qD947P4vZFYltn\nj9utOLVji9hn29YdAVlr/XssxWSX4kxRTjhJXPaHtbe4E4EWQ/IthCWbDENXdEWJAKroihIBVNEV\nJQKooitKBFBFV5QI0BSr+9RE0Jrpy5JFObdaSio/I6csI5mQG3PZoEXel/V2ykEcPe1u62h+XLa6\nDy6Sc66NHH6iKHtmg5zFdvUaue34hX1O+cSE3GfogGCeOV8WJyf2KxZki3xPze0ZmNwWvAd8MsVg\n7rru/iUALOxzfy6AiYqcxy11eK9Tng8JkvndfXcHZL1Dnrdgw3r5MydCLeFywIsjhgaAkmP9nanL\n4qXgXM0FXdEVJQKooitKBFBFV5QIoIquKBFAFV1RIoAquqJEgDm514wxhwI/B66rV1O9BVgJ+D6T\na6y190r9Ew4Pgy+rhGzgrwmuibhQqgmgEpPda+MOz4Qvm5yUgw9qBbeLamG37JJ7+0kniW2LzbGi\n7F9v/pHYbzgkwCNRdJe22vjyS/L5lh0ckKVavEKDrQuWi/3aa7JLNDe2zSnPVN3uLoBiPujKS/V6\nQT7bp2Q3X8+AHAC0YHipU57Pdol94o4mX1ZJy4E8YTnjSiXZvRkru4OzYrWgvFrz7vlyuTGP+Fxq\nr7UD1wMP7Nb0eWvtLxq6qqIoTWUur+4F4L3soTSyoihvXuZSZLEMlI0xuzddYoz5DLANuMRau30f\njE9RlL1AbK5lWI0xXwG213+jnwzssNY+ZYy5DFhsrb1E6rtjy7raguFgsgVFUfYqorGgoV/21tpd\nf6/fDXwv7O//17WfmnV88TU/44b/+VcAVEP2HjdijJssy8a4Xz26dtbxg89uY9UhgwAkYnLhh8EW\n9zkXdsvXOuUD7xHbDjzsHbOOD1j117z04E+BPRnjZIPQoSuPcspzbUNin5Xvev+s49aBQ5gZfdb7\n94J+sR8NGOPy4+Nin92NcQuPOIvNT98JwM5smDFOLnYhG+NeFvvcdfM1s47Pv/zn3PwPZwCw9sX1\nYr9YXC4oUg0zxjmMbgCxymz5FT95mi9/yItBqOKOuwC46if/KbY15F4zxtxljFlWP1wFPNPIeRRF\naQ5zsbqvBK4FlgIlY8wH8azwdxhjckAWOD/sHDHHrwNfVgmJxnGVpgEIqY5DLR9yPkdglS/rWyCv\n6MNt7jeIo992oNjnoOODLjSf8W1Bl+Jk3c3YUpZz3i1bvFhsq7o+HDA8KOdqK88EP5cvy4VEvRXL\n8htVKe++pSrIrsGXNm6YdbzwiD+Vn/rjM4+L/Y4/Vh7jgmF39ODklPuNA8BVxcmX9S+VXalV4T4F\nqBTl/IZlwW27czRYoqrU4skKU/J9GsZcjHFP4K3au3NXQ1dUFKXp6M44RYkAquiKEgFU0RUlAqii\nK0oEUEVXlAjQlOSQVUeUji/LF+QyQ2khWiuZlJPxJeKyy2X5cDCCype1ZuRn3tL9lzjlR7xTjlBb\naA4X2576j5tnHR8FrHvpOQD2WyJHeQ0fcpjYlh44wClPtnWLfXIzs918HbvI8pPyppitm+TNI+Nb\nNzjllZK88SXTGdwEUsp57qT+fvm7Xr/pSbFtaOGIU17OhURL5oOllXxZbFre8FOpuSMHAWou33Kd\nTIv7s6WHg/KBumyyRY6UC0NXdEWJAKroihIBVNEVJQKooitKBFBFV5QIoIquKBGgKe61VCJ4GV82\nHpL8rzLjdiVk2uT430RcdmcMOiLUfNn6zcGIIZ8Djj7VKV98mFvuIbvJSlPToqy7U3aHDRx4pNg2\nnXTXKHv2ycfEPoX87HG8b8U7eOyR3wAwOSnPx/aNr4ptiYrbvdnaKt9qI28JusKKk17mssMPlJNU\nlhNyRFkq0eOWp+XoxuRMMN7fl+XWbRT7udzHPuWQpTQr1AlsWxD8XKVJbxxDITX9wtAVXVEigCq6\nokQAVXRFiQCq6IoSAVTRFSUCNMXqXsgHrZm+rK1FHkKs1W2VTMXlnGW1ityW6Qier7MuO/3s08V+\nx7/nZKe8q1/OsLr15efFtoRj/L5sYkrOGTf6ihXbNk25Lb8P/uxnYp+OzOzgifed9wX++NC/ATBT\nkIM/hodkz0BXp9sSvnaDHAhTdMzH2nXrAOhbtFTsd+BhK8U2Ki1O8diEO+gGIOfw8viy8bx8X8Vq\n8j08k5eDtrJCqvVaNqgvq9d5soPczoQ9oiu6okQAVXRFiQCq6IoSAVTRFSUCqKIrSgRQRVeUCDAn\n95ox5mrghPrffw14DLgdSACbgXOttcGEW3WqtWCgw2uyqhwQECu7XRPlWkjZpZAcXa0tXQFZqsXL\nV3bkStlV05Jy5/Z67ik5Z9n4ppfEtkLB4W6sy6bGx8R+69c8J7Zla+5An1RFLszYkQy6GzuS3px3\ntcoBIwO9sntt89YtTnk5pPRWbiroyvNl69fKATTwrNiSzbpz3rUm5fuj3DIoynaUg/eOTyYjFz5s\n65QDsDJJtwtwKjcZ/NtWL0iqXJXdfGHscUU3xpwEHGqtPQ44Ffg2cCVwg7X2BGANcEFDV1cUpSnM\n5dX9IeCs+r8ngHa8Wmx312X3AO/a6yNTFGWvMZciixXAD1y+ELgPePcur+rbgIX7ZniKouwNYjVh\nG97uGGPOAP4e+EvgRWvtYF2+HLjNWnu81Hf7prW1/kVv2QvDVRQlBDHp+1yNce8GLgdOtdbuNMZk\njTEZa20eGAE2hfX/8VV/M+v4b7/3AN/+hLd/fGKLvPc4nhYMQrUQA16IMa6tZ7ZB5bM3Psy1F70T\ngDM+8jGx38LlRznlL691G54g3Bi38ZnfzTr+0Jdu5ydXngvA1OYXxX4HHnyQ2CYZ45743SNinwU9\ns+f3kht/x3cvegcA8aRcKGBooZzlRDLG7ZiUixx0LphtBPvMt+7nW5/xfg0uXSEXrVjyFjnjTiPG\nuD888fCs44uuuoMbv3g2AI8//rCrC7AHY1yLbIyLz9EYd/1dL/LJM1cAsHiFbBT83NefkK8lttQx\nxnQD1wCnWWt9k/D9wJn1f58J/HJP51EUZf6Yy4p+NtAP/NQY48vOA/7RGHMRsA64NfwULjeZJ6uW\n5RJKyVQwxxtAJSRHVxHZ/TDUHczj1lmX/dvdvxD79Q253TiDC92lmgCKOTkKLZUKPsl9WUe7/MRO\nxt3RfADtggtweFBeffNTwTJD5YK38mYS7tUGYMfodrGtVHR/N52t8spWzAbda77sxScfF/ttfmG1\n2FYoC28QKXkOK475nZz2vsf2xbK7kXb5Ho63yO7NVsFV1ktwrvZb5skOOqSxn8BzMcbdBNzkaDql\noSsqitJ0dGecokQAVXRFiQCq6IoSAVTRFSUCqKIrSgRoSnLIajW4+cKXpR0RVD6tSSGxXlzezFEL\nKdNTLQYjqHzZ9u3y5pfsqLstUwpGGb12XuTP1dcbdHn5sp5FA2K/ckUMEGTjJvcYa8gbROLx4Nfv\ny4pl2U2ZiLldeQDtrW6XqBCI6J3P0Zjxy3iFbICqFGUXZtxxzwFM5oIuRZ9iS9AltzP3CgCdi+S5\nn87I5aumqrLrbWbavc4u6FoWkLX1e/PQH+IuDUNXdEWJAKroihIBVNEVJQKooitKBFBFV5QIoIqu\nKBGgKe61eCwYCeXLWkPidWtCJFp7xu3CAWjv7BfbcqVgJFGt5LlNFnSmxX5JYRzFnVvFPtW4fL5c\nKuhOyuW8+OmhITk6qVqUXTXm8MVO+SO/eUDsU6zlHDLv2Z+KyS7MfDbYz6er0x19l07Kt1oiFpyP\n1pT399kZOfpr7WbZVTYx4f7OCrFppxxg4MDgujdW9lyoIz0h0Xc1+bse3y7PVXrG7aZsHwm60No7\nPVk+J0duhqEruqJEAFV0RYkAquiKEgFU0RUlAqiiK0oEaIrVPZ0MPk98Wa4gBwskhLJA1ZB8ZrmS\nnG00kQoGSCQSnsW3JS1bVVMp9zjSbXJpou4uObhmy2jQWj81PgpAbsRtPQcYXLJcbNu4zZ3H7ZC3\nv0Pskx0NJu896Mi3AfDyarnc0XRWDuJIJtzz390t58KLOXIK+rLNG+UEw6+uCwlqaXHPf9eQ7LEZ\n6AuOcaDPy1AbC7H+x8bk77p3XFaxkcE+p3xxT/Ae8GVrnpODr076gNikK7qiRAFVdEWJAKroihIB\nVNEVJQKooitKBFBFV5QIMNcii1cDJ9T//mvA6cBKYEf9T66x1t4r9R8aCD5PfFlpx45Am0++4k40\nNi3HJVCLy5v+k47AismdXjBJV5eciystlDvKT8s54zKpkKktOtrqsscfkYsiLjNyEM2GDW63Szwk\nv15bS/BzZSc9l1UixIWZycjupOms272Wz8tuz7KjLNfmzd7n6cjI4zj+qAPFtlYhuKackHPhVUrB\nAJS2kjdH+fWyey0+JRdZHGzrFNuOOvAQd5+eoYBsuC57YvNa8Xxh7FHRjTEnAYdaa48zxiwAngT+\nHfi8tVYuWKYoypuGuazoDwGP1v89AbRDSIpTRVHedMylyGIF8F+WLwTuAyrAJcaYzwDbgEustXKJ\nTUVR5pVYrSbnzd4VY8wZwN8Dfwm8DdhhrX3KGHMZsNhae4nUd+e2dbXuwf33xngVRZERDTJzNca9\nG7gcONVauxPYNW3J3cD3wvrf/73Zz4Azv3wPd13xfgA2vCAbn/KVYD1zgFhCNnC8HmPcpbf+nm+e\ndzQQboxry7j3tCcS8kOyr8e9jxlgbGx2PfAPfeMn/ORzHwJgYmZK7LfMHCC27Q1j3NlfvJ07rjoX\ngB2jo2K/ybGw+uhuo1VIafeAMe7Ld67mirM8Q1vYQtSa6ZHbGjHGJWcb4z533WN849NvByBfkL+X\notxEV5tc7OKY4wRj3ODIrOND33stz9z3WQDuve//iuf73Hd/J7bt0b1mjOkGrgFOs9aO1WV3GWP8\nchKrgGf2dB5FUeaPuazoZwP9wE+NMb7sZuAOY0wOyALnh51gvyXBnFq+rDsmuybWrHfn29o6Kj/l\nixXZHdPREfy4pfpiMp2TI6Eq1axTngh5To6Nym7DqWxwVVm3bj0AMyV5HIma3NbZ4X772bplTOyz\nYTq4+q5+7nkAqjX5TWBoQH77iVWDZa8Axifk/G4t7cHvrL3de2vr6Zbf3tIJef4LReHNLimvsNOF\n4Pla6rJiNqQMVVUex/Ilw2LbomH3PK7fMNuNeiiweZMn2zEq56ALYy7GuJuAmxxNtzZ0RUVRmo7u\njFOUCKCKrigRQBVdUSKAKrqiRABVdEWJAE1JDtnVG3RN+LJ8iLugd1DYZdEuJ/jbvlVONjnjKGk0\nU/Qi0JJpOXmhVAmpWpI355Qq8jh25oOupp35zQC0h0RrzeTkCKr8jHsTSzFkjBVHmy+r1eQdLtnJ\nkJJMXe4km11dciLNfD54vlg9nGL7Dtkt19EhR9HF4u41LFaWXbPpZHDsvqxF9gKTTstztXT5UrEt\nn3OP5aGHnpt1fMrf/En2h9Xb5IGEoCu6okQAVXRFiQCq6IoSAVTRFSUCqKIrSgRQRVeUCNAU91qy\nNXgZX9baFYxs8+nrcD+HknnZdZXKuBNKAkw66mD1DNSjrSryMy/TOuiUV1LytSoFuT5Zui04Dl+W\nSsrzkUjIbsVCzT2WYknwDQI1R4SaL4uF5COpCTHnABWhKRUSNUY66FLM1GUT47J7LV90R8oBdPe4\n3aVJwe0GEHfMfTXhjTuHHMe+dbsckD7uiFT0mZp2RyPe/+ALs46v2kW2tbHgNV3RFSUKqKIrSgRQ\nRVeUCKCKrigRQBVdUSKAKrqiRICmuNeyjsR6r8kSHWK/jna3ryaVkX0/7SFhRt3dQRfUkqXesy47\nKdcGy066a55lcyHRazNyW2eFkzKcAAAGvUlEQVQ6mBSwM+XJWoU6bwDlguxWTCbdz+x0yKM81RKM\numqry2IxuWObI8mmT1xoKldkN1M643A31mVdPbJLcWxMdmtNCe7Grj45sWXOUQMum/dkL74iJ/t8\n4Y/rxbahPjkqcmix8NnijrHXZf0hyTLD0BVdUSKAKrqiRABVdEWJAKroihIBVNEVJQLs0epujGkD\nbgGGgFa8PfZPA7fj1UnfDJxrrRVNwhvWzT4+YhdZYUK2kncOuC21rZmQYAbZiE9fX/Dj7rfEk2Wn\n5WiBiQl32/gOOQBlXDbSkqgGrd2JpOdhqIYUFaxUZEs+VXdb2JM85ijAmKzLEkn51siHBADVBON6\nSijVBFDOBctG5ce9Io8VRz45n0pIoMxE1t1PqtQEMObwvKxb8woAr6yRv9CJHdNiW3FavuBwt7tc\n00H7j4iyEOdQKHNZ0d8PPG6tPRH4a+BbwJXADdbaE4A1wAWNXV5RlGYwl9prd+xyuATYgFdB9eN1\n2T3ApeyhdLKiKPPHnDfMGGMeARYDpwH37/Kqvg1YuA/GpijKXiIWVmh+d4wxRwK3AQuttQN12XLg\nNmvt8VK/qe0bap39i9/oWBVFCUesdT0XY9xKYJu1dr219iljTBKYMsZkrLV5YATYFHaOh2754qzj\n9116M/d+0yupXph4VOzXOeCuSx5mjEum3AUEABK77Qc95pwXefSfVgCQnZa3aE4IyWIaN8bNLjzw\n6R/9nusuONprQy7gUC7JY5S+4mpVfpDHdjPRfPbHj3Lth4/xxhFi6CoL220BpHUjVZXHnqjM3sr6\nydue4fqPHArAdIgxbqwsj7E047ZatWVCttTuZun63v3r+MS79gfgDyHGuC2bZGPc+R86Tmx7+zEr\nnPI7fvrwrOMf/fYlLjjxACDcGPcvj74kts3FGPdfgc8CGGOGgA7gfuDMevuZwC/ncB5FUeaJufxG\n/z7wQ2PM/wEywMXA48BtxpiLgHXArWEnqKT6RVkp/TaxX6Hq9tjFy+7yQwCt3eLbCz0DQVde78K3\nev+PyytOX84dIDExJr89TGyXy/Tkp4PTPnyA93SvlOW3BGryc7lado9xJi/nd0ung9dasMQbRyIp\nj39qRs6Vl88KgUg1OXddZzwYqNHdsQiAanxS7FcqybdvS7v71aI1Jb8x9aSDY+zpXwLAMnrEfocd\nIZeGMocfIbYtXb7cKT/m2OBbzDHHem98Gza533L3xFys7nngvzuaTmnoioqiNB3dGacoEUAVXVEi\ngCq6okQAVXRFiQCq6IoSAV7XzjhFUf7/RFd0RYkAquiKEgFU0RUlAqiiK0oEUEVXlAigiq4oEaAp\nJZl8jDHXAccCNeBT1trHmnn9+hhWAXcCz9ZFf7TWfrLJYzgU+DlwnbX2u8aYJbyOZJv7cBy3ACsB\nP/j6GmvtvU0Yx9XACXj349eAx5if+dh9HKfTxPnYG4lYJZq2ohtjTgRWWGuPAy4EvtOsazv4rbV2\nVf2/Zit5O3A98MAu4qYn2xTGAfD5XeamGUp+EnBo/b44Ffg28zMfrnFAc+djnyVibear+8nAzwCs\ntc8DvcYYuQLdny8F4L3MzsqzCri7/u97gHfN0zjmg4eAs+r/ngDamZ/5cI1DDsrfB1hr77DWXl0/\n3DUR6xuei2a+ug8DT+xyPFqXyZkF9h0HG2PuBvqAK6y1v27Wha21ZaBsjNlV3N7sZJvCOAAuMcZ8\npj6OS6y1cpaPvTOOCuDnYroQuA949zzMh2scFZo8H7BvErHOpzFOTgWzb3kRuAI4AzgPL3tOSFqX\npjNf8wLeb8HLrLV/ATwFfKVZFzbGnIGnYJfs1tTU+dhtHPMyH/VEq6cDP2b25294Lpqp6JvwVnCf\nRXjGhaZird1Yf0WqWWtfArbgJbicT7LGGD8v1R6Tbe4rrLUPWGufqh/eDRzWjOsaY94NXA68x1q7\nk3maj93H0ez5MMasrBtmqV/3tUSs9T9peC6aqei/Aj4IYIw5GthkrZUr2e8jjDHnGGMurf97GM/C\nubHZ49iNN0WyTWPMXcaYZfXDVcAzTbhmN3ANcJq11q/N1PT5cI1jHuZjnyVibWr0mjHm63gfpgpc\nbK19umkX/9MYOoF/BnqANN5v9PuaeP2VwLXAUqCE95A5B8+t0oqXbPN8a62c03rfjeN64DIgB2Tr\n49i2j8fxMbxX4tW7iM8D/pHmzodrHDfjvcI3ZT7qK/cP8QxxGbyfmI/j1VJ4Q3OhYaqKEgF0Z5yi\nRABVdEWJAKroihIBVNEVJQKooitKBFBFV5QIoIquKBFAFV1RIsD/A08iPzTQ+yKFAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Ilj2ZjQ2eX3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3f56fe37-cc04-4e51-adee-114137a179ef"
      },
      "cell_type": "code",
      "source": [
        "show_example(cv_images, cv_labels, example_index = 0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  [3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuqLEADV0RYkB/w8OoEb2ZrT8nQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "e-K-vXgWLVae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "fUgPArynjJ49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "train_y = np_utils.to_categorical(train_labels, num_classes)\n",
        "cv_y = np_utils.to_categorical(cv_labels, num_classes)\n",
        "\n",
        "train_images = train_images.astype('float32')\n",
        "cv_images = cv_images.astype('float32')\n",
        "train_images /= 255\n",
        "cv_images /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HIZnC3-eX31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building AlexNet"
      ]
    },
    {
      "metadata": {
        "id": "DzXazbS4pYlN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_AlexNet(num_classes=10, k=1):\n",
        "  model = Sequential()\n",
        "  # 1\n",
        "  model.add(Conv2D(48 * k, (11, 11), strides=(4,4), padding='same',\n",
        "                   input_shape=train_images.shape[1:]))\n",
        "\n",
        "  model.add(BatchNormalization(name=\"1_bn\"))\n",
        "  model.add(Activation('relu', name=\"1_relu\"))\n",
        "  model.add(MaxPooling2D((3, 3), strides=(2,2), padding='same', name=\"1_maxpool\"))\n",
        "  \n",
        "  # 2\n",
        "  model.add(Conv2D(128 * k, (5, 5), strides=(1,1), padding='same', name=\"2_conv\"))\n",
        "  model.add(BatchNormalization(name=\"2_bn\"))\n",
        "  model.add(Activation('relu', name=\"2_relu\"))\n",
        "  model.add(MaxPooling2D((3, 3), strides=(2,2), padding='same', name=\"2_maxpool\"))\n",
        "#   if dropout:\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "  # 3\n",
        "  model.add(Conv2D(192 * k, (3, 3),  strides=(1,1), padding='same', name=\"3_conv\"))\n",
        "  model.add(Activation('relu', name=\"3_relu\"))\n",
        "    \n",
        "  # 4\n",
        "  model.add(Conv2D(192 * k, (3, 3),  strides=(1,1), padding='same', name=\"4_conv\"))\n",
        "  model.add(Activation('relu', name=\"4_relu\"))\n",
        "    \n",
        "  # 5\n",
        "  model.add(Conv2D(128 * k, (3, 3),  strides=(1,1), padding='same', name=\"5_conv\"))\n",
        "  model.add(BatchNormalization(name=\"5_bn\"))\n",
        "  model.add(Activation('relu', name=\"5_relu\"))\n",
        "  model.add(MaxPooling2D((3, 3), strides=(2,2), padding='same', name=\"5_maxpool\"))\n",
        "#   if dropout:\n",
        "#     model.add(Dropout(0.5))\n",
        "  \n",
        "  # 6\n",
        "  model.add(Flatten(name=\"6_flatten\"))\n",
        "  model.add(Dropout(0.5, name=\"6_dropout\"))\n",
        "  model.add(Dense(2048 * k, name=\"6_fc\"))\n",
        "  model.add(BatchNormalization(name=\"6_bn\"))\n",
        "  model.add(Activation('relu', name=\"6_relu\"))\n",
        "    \n",
        "  # 7\n",
        "  model.add(Dropout(0.5, name=\"7_dropout\"))\n",
        "  model.add(Dense(2048 * k, name=\"7_fc\"))\n",
        "  model.add(BatchNormalization(name=\"7_bn\"))\n",
        "  model.add(Activation('relu', name=\"7_relu\"))\n",
        "\n",
        "  # 8\n",
        "  model.add(Dense(num_classes, name=\"8_fc\"))\n",
        "  model.add(BatchNormalization(name=\"8_bn\"))\n",
        "  model.add(Activation('softmax', name=\"8_softmax\"))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jU4P8xRseX39",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training AlexNet"
      ]
    },
    {
      "metadata": {
        "id": "Uyh9RCjW0grJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "7786cf3c-06f5-46f5-98c4-709864285745"
      },
      "cell_type": "code",
      "source": [
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://ab1b3544.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ru2OxZ2Qpb-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "outputId": "398232a7-03a0-4773-8183-a0cae8ddf3d0"
      },
      "cell_type": "code",
      "source": [
        "model = create_AlexNet(num_classes)\n",
        "model.summary()\n",
        "\n",
        "sgd = keras.optimizers.SGD(lr=0.01, decay=5*1e-4, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=rmsprop,\n",
        "              metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                              patience=10, cooldown=1,\n",
        "                                              min_lr=0.00001, verbose=1)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_86 (Conv2D)           (None, 8, 8, 48)          17472     \n",
            "_________________________________________________________________\n",
            "1_bn (BatchNormalization)    (None, 8, 8, 48)          192       \n",
            "_________________________________________________________________\n",
            "1_relu (Activation)          (None, 8, 8, 48)          0         \n",
            "_________________________________________________________________\n",
            "1_maxpool (MaxPooling2D)     (None, 4, 4, 48)          0         \n",
            "_________________________________________________________________\n",
            "2_conv (Conv2D)              (None, 4, 4, 128)         153728    \n",
            "_________________________________________________________________\n",
            "2_bn (BatchNormalization)    (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "2_relu (Activation)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "2_maxpool (MaxPooling2D)     (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "3_conv (Conv2D)              (None, 2, 2, 192)         221376    \n",
            "_________________________________________________________________\n",
            "3_relu (Activation)          (None, 2, 2, 192)         0         \n",
            "_________________________________________________________________\n",
            "4_conv (Conv2D)              (None, 2, 2, 192)         331968    \n",
            "_________________________________________________________________\n",
            "4_relu (Activation)          (None, 2, 2, 192)         0         \n",
            "_________________________________________________________________\n",
            "5_conv (Conv2D)              (None, 2, 2, 128)         221312    \n",
            "_________________________________________________________________\n",
            "5_bn (BatchNormalization)    (None, 2, 2, 128)         512       \n",
            "_________________________________________________________________\n",
            "5_relu (Activation)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "5_maxpool (MaxPooling2D)     (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "6_flatten (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "6_dropout (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "6_fc (Dense)                 (None, 2048)              264192    \n",
            "_________________________________________________________________\n",
            "6_bn (BatchNormalization)    (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "6_relu (Activation)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "7_dropout (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "7_fc (Dense)                 (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "7_bn (BatchNormalization)    (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "7_relu (Activation)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "8_fc (Dense)                 (None, 10)                20490     \n",
            "_________________________________________________________________\n",
            "8_bn (BatchNormalization)    (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "8_softmax (Activation)       (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 5,444,530\n",
            "Trainable params: 5,435,710\n",
            "Non-trainable params: 8,820\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AxHr9pt5mYmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3096
        },
        "outputId": "4977257a-0e8c-4c69-a8bd-3bc7efe34665"
      },
      "cell_type": "code",
      "source": [
        "epoch_start = 0\n",
        "batch_size = 128\n",
        "epochs = 90\n",
        "\n",
        "model.fit(train_images, train_y,\n",
        "      initial_epoch=epoch_start,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      shuffle=True,\n",
        "      validation_data=(cv_images, cv_y),\n",
        "      callbacks=[reduce_lr, TensorBoardColabCallback(tbc)])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/90\n",
            "50000/50000 [==============================] - 17s 330us/step - loss: 1.8845 - acc: 0.2605 - val_loss: 2.6133 - val_acc: 0.2209\n",
            "Epoch 2/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.5592 - acc: 0.4110 - val_loss: 1.9342 - val_acc: 0.3510\n",
            "Epoch 3/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.3378 - acc: 0.5117 - val_loss: 2.1123 - val_acc: 0.3516\n",
            "Epoch 4/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.2160 - acc: 0.5639 - val_loss: 1.6544 - val_acc: 0.4330\n",
            "Epoch 5/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.1181 - acc: 0.6056 - val_loss: 1.9566 - val_acc: 0.4015\n",
            "Epoch 6/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.0463 - acc: 0.6357 - val_loss: 1.4255 - val_acc: 0.5409\n",
            "Epoch 7/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.9789 - acc: 0.6610 - val_loss: 1.3584 - val_acc: 0.5561\n",
            "Epoch 8/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.9185 - acc: 0.6847 - val_loss: 1.5217 - val_acc: 0.5252\n",
            "Epoch 9/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.8671 - acc: 0.7050 - val_loss: 1.5529 - val_acc: 0.5362\n",
            "Epoch 10/90\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 0.8154 - acc: 0.7230 - val_loss: 1.2105 - val_acc: 0.6092\n",
            "Epoch 11/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.7687 - acc: 0.7403 - val_loss: 1.4327 - val_acc: 0.5541\n",
            "Epoch 12/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.7251 - acc: 0.7554 - val_loss: 1.2913 - val_acc: 0.6049\n",
            "Epoch 13/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.6793 - acc: 0.7711 - val_loss: 1.1537 - val_acc: 0.6414\n",
            "Epoch 14/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.6394 - acc: 0.7895 - val_loss: 1.1586 - val_acc: 0.6404\n",
            "Epoch 15/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.6027 - acc: 0.8005 - val_loss: 1.3850 - val_acc: 0.6027\n",
            "Epoch 16/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.5702 - acc: 0.8113 - val_loss: 1.2486 - val_acc: 0.6326\n",
            "Epoch 17/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5382 - acc: 0.8221 - val_loss: 1.2626 - val_acc: 0.6276\n",
            "Epoch 18/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.5063 - acc: 0.8329 - val_loss: 1.3109 - val_acc: 0.6251\n",
            "Epoch 19/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.4812 - acc: 0.8430 - val_loss: 1.4308 - val_acc: 0.6116\n",
            "Epoch 20/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.4471 - acc: 0.8545 - val_loss: 1.5366 - val_acc: 0.5981\n",
            "Epoch 21/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.4278 - acc: 0.8599 - val_loss: 1.5613 - val_acc: 0.5963\n",
            "Epoch 22/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.3971 - acc: 0.8707 - val_loss: 1.5547 - val_acc: 0.6166\n",
            "Epoch 23/90\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 0.3771 - acc: 0.8777 - val_loss: 1.3436 - val_acc: 0.6366\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 24/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.2190 - acc: 0.9352 - val_loss: 1.2748 - val_acc: 0.6786\n",
            "Epoch 25/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.1705 - acc: 0.9497 - val_loss: 1.3555 - val_acc: 0.6754\n",
            "Epoch 26/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.1522 - acc: 0.9576 - val_loss: 1.4004 - val_acc: 0.6740\n",
            "Epoch 27/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.1373 - acc: 0.9612 - val_loss: 1.4625 - val_acc: 0.6724\n",
            "Epoch 28/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.1275 - acc: 0.9641 - val_loss: 1.5206 - val_acc: 0.6762\n",
            "Epoch 29/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.1139 - acc: 0.9680 - val_loss: 1.5750 - val_acc: 0.6706\n",
            "Epoch 30/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.1074 - acc: 0.9695 - val_loss: 1.6210 - val_acc: 0.6732\n",
            "Epoch 31/90\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 0.0999 - acc: 0.9722 - val_loss: 1.6570 - val_acc: 0.6719\n",
            "Epoch 32/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.0917 - acc: 0.9751 - val_loss: 1.7133 - val_acc: 0.6706\n",
            "Epoch 33/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.0884 - acc: 0.9756 - val_loss: 1.7357 - val_acc: 0.6723\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "Epoch 34/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0747 - acc: 0.9803 - val_loss: 1.7285 - val_acc: 0.6742\n",
            "Epoch 35/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0715 - acc: 0.9819 - val_loss: 1.7369 - val_acc: 0.6743\n",
            "Epoch 36/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0691 - acc: 0.9821 - val_loss: 1.7461 - val_acc: 0.6735\n",
            "Epoch 37/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0694 - acc: 0.9818 - val_loss: 1.7562 - val_acc: 0.6752\n",
            "Epoch 38/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0690 - acc: 0.9821 - val_loss: 1.7610 - val_acc: 0.6742\n",
            "Epoch 39/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0668 - acc: 0.9823 - val_loss: 1.7672 - val_acc: 0.6738\n",
            "Epoch 40/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0643 - acc: 0.9835 - val_loss: 1.7784 - val_acc: 0.6731\n",
            "Epoch 41/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0633 - acc: 0.9838 - val_loss: 1.7871 - val_acc: 0.6734\n",
            "Epoch 42/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0641 - acc: 0.9836 - val_loss: 1.7936 - val_acc: 0.6745\n",
            "Epoch 43/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.0634 - acc: 0.9843 - val_loss: 1.7999 - val_acc: 0.6726\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 44/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0628 - acc: 0.9839 - val_loss: 1.8007 - val_acc: 0.6730\n",
            "Epoch 45/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0625 - acc: 0.9842 - val_loss: 1.8015 - val_acc: 0.6733\n",
            "Epoch 46/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0612 - acc: 0.9844 - val_loss: 1.7993 - val_acc: 0.6735\n",
            "Epoch 47/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0598 - acc: 0.9845 - val_loss: 1.8040 - val_acc: 0.6735\n",
            "Epoch 48/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0612 - acc: 0.9845 - val_loss: 1.8072 - val_acc: 0.6733\n",
            "Epoch 49/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0602 - acc: 0.9847 - val_loss: 1.8074 - val_acc: 0.6733\n",
            "Epoch 50/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.0608 - acc: 0.9844 - val_loss: 1.8094 - val_acc: 0.6734\n",
            "Epoch 51/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0613 - acc: 0.9843 - val_loss: 1.8076 - val_acc: 0.6734\n",
            "Epoch 52/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0618 - acc: 0.9843 - val_loss: 1.8126 - val_acc: 0.6738\n",
            "Epoch 53/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0623 - acc: 0.9841 - val_loss: 1.8107 - val_acc: 0.6726\n",
            "Epoch 54/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0615 - acc: 0.9844 - val_loss: 1.8089 - val_acc: 0.6726\n",
            "Epoch 55/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0611 - acc: 0.9845 - val_loss: 1.8139 - val_acc: 0.6729\n",
            "Epoch 56/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0600 - acc: 0.9849 - val_loss: 1.8144 - val_acc: 0.6733\n",
            "Epoch 57/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0591 - acc: 0.9850 - val_loss: 1.8103 - val_acc: 0.6728\n",
            "Epoch 58/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0605 - acc: 0.9845 - val_loss: 1.8132 - val_acc: 0.6734\n",
            "Epoch 59/90\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 0.0606 - acc: 0.9846 - val_loss: 1.8119 - val_acc: 0.6722\n",
            "Epoch 60/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0615 - acc: 0.9842 - val_loss: 1.8170 - val_acc: 0.6733\n",
            "Epoch 61/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0606 - acc: 0.9843 - val_loss: 1.8173 - val_acc: 0.6726\n",
            "Epoch 62/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0613 - acc: 0.9846 - val_loss: 1.8187 - val_acc: 0.6717\n",
            "Epoch 63/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0609 - acc: 0.9846 - val_loss: 1.8134 - val_acc: 0.6728\n",
            "Epoch 64/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0602 - acc: 0.9847 - val_loss: 1.8144 - val_acc: 0.6729\n",
            "Epoch 65/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0584 - acc: 0.9848 - val_loss: 1.8156 - val_acc: 0.6737\n",
            "Epoch 66/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0590 - acc: 0.9850 - val_loss: 1.8190 - val_acc: 0.6724\n",
            "Epoch 67/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0598 - acc: 0.9852 - val_loss: 1.8200 - val_acc: 0.6734\n",
            "Epoch 68/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0598 - acc: 0.9849 - val_loss: 1.8194 - val_acc: 0.6736\n",
            "Epoch 69/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0603 - acc: 0.9849 - val_loss: 1.8229 - val_acc: 0.6727\n",
            "Epoch 70/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0604 - acc: 0.9842 - val_loss: 1.8186 - val_acc: 0.6734\n",
            "Epoch 71/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0596 - acc: 0.9855 - val_loss: 1.8230 - val_acc: 0.6728\n",
            "Epoch 72/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0599 - acc: 0.9848 - val_loss: 1.8251 - val_acc: 0.6740\n",
            "Epoch 73/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0576 - acc: 0.9851 - val_loss: 1.8240 - val_acc: 0.6735\n",
            "Epoch 74/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0591 - acc: 0.9851 - val_loss: 1.8243 - val_acc: 0.6732\n",
            "Epoch 75/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0617 - acc: 0.9841 - val_loss: 1.8208 - val_acc: 0.6730\n",
            "Epoch 76/90\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 0.0586 - acc: 0.9852 - val_loss: 1.8245 - val_acc: 0.6730\n",
            "Epoch 77/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0589 - acc: 0.9851 - val_loss: 1.8240 - val_acc: 0.6726\n",
            "Epoch 78/90\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 0.0616 - acc: 0.9841 - val_loss: 1.8257 - val_acc: 0.6729\n",
            "Epoch 79/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0584 - acc: 0.9859 - val_loss: 1.8214 - val_acc: 0.6730\n",
            "Epoch 80/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0591 - acc: 0.9852 - val_loss: 1.8284 - val_acc: 0.6731\n",
            "Epoch 81/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0572 - acc: 0.9853 - val_loss: 1.8241 - val_acc: 0.6725\n",
            "Epoch 82/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0598 - acc: 0.9851 - val_loss: 1.8279 - val_acc: 0.6726\n",
            "Epoch 83/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0594 - acc: 0.9845 - val_loss: 1.8316 - val_acc: 0.6733\n",
            "Epoch 84/90\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 0.0577 - acc: 0.9850 - val_loss: 1.8288 - val_acc: 0.6724\n",
            "Epoch 85/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0600 - acc: 0.9848 - val_loss: 1.8305 - val_acc: 0.6732\n",
            "Epoch 86/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0574 - acc: 0.9854 - val_loss: 1.8328 - val_acc: 0.6719\n",
            "Epoch 87/90\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 0.0579 - acc: 0.9854 - val_loss: 1.8331 - val_acc: 0.6718\n",
            "Epoch 88/90\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 0.0582 - acc: 0.9854 - val_loss: 1.8344 - val_acc: 0.6722\n",
            "Epoch 89/90\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 0.0582 - acc: 0.9850 - val_loss: 1.8319 - val_acc: 0.6729\n",
            "Epoch 90/90\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 0.0580 - acc: 0.9851 - val_loss: 1.8306 - val_acc: 0.6732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fKH5npU69w4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "9dacf827-51a8-43fb-fe9f-48aaba00a43e"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(cv_images, cv_y, verbose=1)\n",
        "print('Test loss: {:.2f}'.format(scores[0]))\n",
        "print('Test accuracy: {:.2f}%'.format(scores[1]*100))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 242us/step\n",
            "Test loss: 1.83\n",
            "Test accuracy: 67.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yfHcRVN6oqcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "87700e36-adf5-4b10-972a-2f92e34f9d7b"
      },
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'alex-net_vanilla.h5'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "if _colab:\n",
        "  model_file = drive.CreateFile({'title' : model_name})\n",
        "  model_file.SetContentFile(model_path)\n",
        "  model_file.Upload()"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/alex-net_vanilla.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gui8_xgHeX4B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Improving AlexNet"
      ]
    },
    {
      "metadata": {
        "id": "qZgZqdXXeX4C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "AlexNet was specifically created for a large-scale ImageNet dataset, that is much more complex than CIFAR-10, e.g. it has images of higher quality (224x224 in ImageNet vs. 32x32 in CIFAR), a huge (1000) number of various classes with its hierarchy (vs. simple 10 in CIFAR), 1.2 million images in total vs. 60 thousand in CIFAR. The architecture is as complex as it should be for such dataset, but for ours, it over-complicated and thus is easy to overfit, as we can see from the classification results above. So to achieve a good generalization, we need to revisit the model and optimization configurations. Also, we suggest using data augmentation to enlarge and diversify training data."
      ]
    },
    {
      "metadata": {
        "id": "taGeyuRIlLOn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_modified_AlexNet():\n",
        "  model = Sequential()\n",
        "  # 1\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                   input_shape=train_images.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  # 2\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # 3\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  \n",
        "  # 4\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # 5\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # 6\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # 7\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  # 8\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6j-qh4xtPJfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_myAACwHETx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = create_modified_AlexNet()\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# rmsprop = keras.optimizers.rmsprop(lr=0.01, decay=1e-6)\n",
        "sgd = keras.optimizers.SGD(lr=0.01, decay=5*1e-4, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=rmsprop,\n",
        "              metrics=['accuracy'])\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                              patience=10, cooldown=1,\n",
        "                                              min_lr=0.00001, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhimEUvWHp8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch_start = 0\n",
        "batch_size = 128\n",
        "epochs = 90\n",
        "\n",
        "model.fit(train_images, train_y,\n",
        "      initial_epoch=epoch_start,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      shuffle=True,\n",
        "      validation_data=(cv_images, cv_y),\n",
        "      callbacks=[reduce_lr, TensorBoardColabCallback(tbc)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOoQj3xmrojQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "fc1008b5-2297-4fb6-90f5-2748a5f36bf5"
      },
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False, \n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.,\n",
        "    zoom_range=0.,\n",
        "    channel_shift_range=0.,\n",
        "    fill_mode='nearest',\n",
        "    cval=0.,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.0)\n",
        "\n",
        "datagen.fit(train_images)\n",
        "\n",
        "epoch_start = 0\n",
        "batch_size = 32\n",
        "epochs = 25\n",
        "\n",
        "model.fit_generator(datagen.flow(train_images, train_y,\n",
        "                                 batch_size=batch_size),\n",
        "                    initial_epoch=epoch_start,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(cv_images, cv_y),\n",
        "                    workers=4, \n",
        "                    steps_per_epoch=1500,  \n",
        "                    callbacks=[TensorBoardColabCallback(tbc)])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 1.8489 - acc: 0.3182 - val_loss: 1.6276 - val_acc: 0.4064\n",
            "Epoch 2/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.5826 - acc: 0.4197 - val_loss: 1.3880 - val_acc: 0.4900\n",
            "Epoch 3/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.4672 - acc: 0.4665 - val_loss: 1.2890 - val_acc: 0.5320\n",
            "Epoch 4/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.3932 - acc: 0.4953 - val_loss: 1.2302 - val_acc: 0.5623\n",
            "Epoch 5/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.3244 - acc: 0.5245 - val_loss: 1.1358 - val_acc: 0.6003\n",
            "Epoch 6/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.2628 - acc: 0.5475 - val_loss: 1.1348 - val_acc: 0.5959\n",
            "Epoch 7/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.2142 - acc: 0.5667 - val_loss: 1.0937 - val_acc: 0.6157\n",
            "Epoch 8/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.1711 - acc: 0.5837 - val_loss: 1.0438 - val_acc: 0.6314\n",
            "Epoch 9/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.1246 - acc: 0.6024 - val_loss: 1.0132 - val_acc: 0.6451\n",
            "Epoch 10/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.0958 - acc: 0.6099 - val_loss: 0.9717 - val_acc: 0.6582\n",
            "Epoch 11/25\n",
            "1500/1500 [==============================] - 45s 30ms/step - loss: 1.0729 - acc: 0.6240 - val_loss: 0.9132 - val_acc: 0.6803\n",
            "Epoch 12/25\n",
            "1500/1500 [==============================] - 44s 29ms/step - loss: 1.0397 - acc: 0.6343 - val_loss: 0.9018 - val_acc: 0.6807\n",
            "Epoch 13/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 1.0257 - acc: 0.6407 - val_loss: 0.9200 - val_acc: 0.6780\n",
            "Epoch 14/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.9876 - acc: 0.6532 - val_loss: 0.8596 - val_acc: 0.7009\n",
            "Epoch 15/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.9816 - acc: 0.6543 - val_loss: 0.8754 - val_acc: 0.7032\n",
            "Epoch 16/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.9615 - acc: 0.6629 - val_loss: 0.8951 - val_acc: 0.6932\n",
            "Epoch 17/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.9440 - acc: 0.6710 - val_loss: 0.8251 - val_acc: 0.7153\n",
            "Epoch 18/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.9394 - acc: 0.6730 - val_loss: 0.8100 - val_acc: 0.7199\n",
            "Epoch 19/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.9198 - acc: 0.6816 - val_loss: 0.7848 - val_acc: 0.7253\n",
            "Epoch 20/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.9080 - acc: 0.6827 - val_loss: 0.8831 - val_acc: 0.6987\n",
            "Epoch 21/25\n",
            "1500/1500 [==============================] - 46s 31ms/step - loss: 0.8983 - acc: 0.6889 - val_loss: 0.8270 - val_acc: 0.7098\n",
            "Epoch 22/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.8983 - acc: 0.6908 - val_loss: 0.7646 - val_acc: 0.7360\n",
            "Epoch 23/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.8843 - acc: 0.6928 - val_loss: 0.7798 - val_acc: 0.7326\n",
            "Epoch 24/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.8754 - acc: 0.6954 - val_loss: 0.7551 - val_acc: 0.7438\n",
            "Epoch 25/25\n",
            "1500/1500 [==============================] - 46s 30ms/step - loss: 0.8802 - acc: 0.6943 - val_loss: 0.7581 - val_acc: 0.7352\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 1s 148us/step\n",
            "Test loss: 0.7581126321792603\n",
            "Test accuracy: 0.7352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ev1q8LFUeX3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use training set for training the network to recognize objects. You might want to use RMSProp optimizer to speed up the training.\n",
        "\n",
        "Convolutional networks require a lot of computing power for training. Typical setup for training CNN is to use GPU, however, in this problem you are not required to do so. CPU will be fine as well.\n",
        "\n",
        "If you are using CPU for this subproblem, training process might be slow. You can stop it manually as soon as you get meaningful results.\n",
        "\n",
        "Report the results on the training and cross-validation sets. The report should contain the training logs."
      ]
    },
    {
      "metadata": {
        "id": "AWFVWdrUeX3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# _train = True\n",
        "# epoch_start = 19\n",
        "# if _train:\n",
        "#     my_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#     my_model.fit(train_images, train_y,\n",
        "#                  initial_epoch=epoch_start,\n",
        "#                  epochs=92,\n",
        "#                  batch_size=256,\n",
        "#                  shuffle=True,\n",
        "#                  validation_data=(cv_images, cv_y),\n",
        "#                  callbacks=[TensorBoardColabCallback(tbc)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHfR-ST-rb0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}