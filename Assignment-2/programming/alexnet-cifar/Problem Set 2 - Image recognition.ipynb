{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cuda = True\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "if cuda:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we have briefly reviewed the idea of learning good features directly from data and went through the concept of convolutional neural networks along with few architectures.\n",
    "\n",
    "Until recently, building convolutional neural networks was tough. There was no high-level tools for that, you would be required to understand all the internal mechanics of the model and its operations.\n",
    "\n",
    "Today, due to the high-level tools such as Keras and TensorFlow, everybody can build a convolutional neural network and put it to work without diving deep into them. What used to be a one-month project became a few hours exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = pickle.load(open('data/train_set_all.pkl', 'rb'))\n",
    "cv_images, cv_labels = pickle.load(open('data/test_set_all.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(cv_images.shape)\n",
    "print(len(cv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 9, 4, 1, 1, 2, 7, 8, 3]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(np_array):\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.imshow(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(data_set, labels, example_index):\n",
    "    show_image(data_set[example_index])\n",
    "    print('Label: ', labels[example_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(train_images, train_labels, example_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(cv_images, cv_labels, example_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "train_y = np_utils.to_categorical(train_labels, 10)\n",
    "cv_y = np_utils.to_categorical(cv_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2012 a convolutional neural network called AlexNet won ImageNet competition. \n",
    "\n",
    "Go through an [original AlexNet paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) to investigate the architecture. Next, investigate the [basics of Keras](https://keras.io/#keras-the-python-deep-learning-library). We will use it with TensorFlow backend.\n",
    "\n",
    "You are also encouraged to go through some CNN tutorial for Keras. There is a number of them online (for example, [this](https://elitedatascience.com/keras-tutorial-deep-learning-in-python) or [this](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)).\n",
    "Now, build AlexNex network with Keras for object recognition. Note that standard AlexNet works with 224x224 input images. The dataset you are going to use for this problem is 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 8, 8, 48)          17472     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 128)         153728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 2, 2, 192)         221376    \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 2, 2, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 2, 2, 128)         221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2048)              264192    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 5,426,890\n",
      "Trainable params: 5,426,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def create_conv_net():\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "\n",
    "    x = Conv2D(48, (11, 11), strides=(4,4), padding='same', activation='relu')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, (5, 5),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(192, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input_img, output, name=\"classifier\")\n",
    "    return model\n",
    "\n",
    "my_model = create_conv_net()\n",
    "my_model.summary()\n",
    "plot_model(my_model, to_file='my_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use training set for training the network to recognize objects. You might want to use RMSProp optimizer to speed up the training.\n",
    "\n",
    "Convolutional networks require a lot of computing power for training. Typical setup for training CNN is to use GPU, however, in this problem you are not required to do so. CPU will be fine as well.\n",
    "\n",
    "If you are using CPU for this subproblem, training process might be slow. You can stop it manually as soon as you get meaningful results.\n",
    "\n",
    "Report the results on the training and cross-validation sets. The report should contain the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('tb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/92\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.2109 - acc: 0.9364 - val_loss: 2.8450 - val_acc: 0.5734\n",
      "Epoch 2/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.1793 - acc: 0.9480 - val_loss: 3.0017 - val_acc: 0.5568\n",
      "Epoch 3/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.1959 - acc: 0.9420 - val_loss: 3.0865 - val_acc: 0.5864\n",
      "Epoch 4/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.1632 - acc: 0.9530 - val_loss: 2.9483 - val_acc: 0.5756\n",
      "Epoch 5/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.7732 - acc: 0.7675 - val_loss: 1.6902 - val_acc: 0.5427\n",
      "Epoch 6/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.4456 - acc: 0.8672 - val_loss: 2.3294 - val_acc: 0.5949\n",
      "Epoch 7/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.1870 - acc: 0.9472 - val_loss: 2.4778 - val_acc: 0.6082\n",
      "Epoch 8/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.1120 - acc: 0.9697 - val_loss: 2.8401 - val_acc: 0.6059\n",
      "Epoch 9/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0800 - acc: 0.9810 - val_loss: 3.0304 - val_acc: 0.6088\n",
      "Epoch 10/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0853 - acc: 0.9792 - val_loss: 3.2010 - val_acc: 0.6072\n",
      "Epoch 11/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0822 - acc: 0.9798 - val_loss: 2.8682 - val_acc: 0.6033\n",
      "Epoch 12/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0601 - acc: 0.9847 - val_loss: 3.3249 - val_acc: 0.6186\n",
      "Epoch 13/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0882 - acc: 0.9782 - val_loss: 3.0948 - val_acc: 0.6104\n",
      "Epoch 14/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.1652 - acc: 0.9589 - val_loss: 2.3319 - val_acc: 0.6058\n",
      "Epoch 15/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.2702 - acc: 0.9243 - val_loss: 2.8173 - val_acc: 0.6126\n",
      "Epoch 16/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.1006 - acc: 0.9743 - val_loss: 3.1116 - val_acc: 0.6145\n",
      "Epoch 17/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0362 - acc: 0.9931 - val_loss: 3.3642 - val_acc: 0.6152\n",
      "Epoch 18/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0257 - acc: 0.9955 - val_loss: 3.6775 - val_acc: 0.6157\n",
      "Epoch 19/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0411 - acc: 0.9911 - val_loss: 3.2416 - val_acc: 0.6135\n",
      "Epoch 20/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0530 - acc: 0.9890 - val_loss: 3.4183 - val_acc: 0.6106\n",
      "Epoch 21/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0517 - acc: 0.9883 - val_loss: 3.4520 - val_acc: 0.6130\n",
      "Epoch 22/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0459 - acc: 0.9909 - val_loss: 3.4530 - val_acc: 0.6102\n",
      "Epoch 23/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0693 - acc: 0.9849 - val_loss: 3.3843 - val_acc: 0.6116\n",
      "Epoch 24/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.1091 - acc: 0.9748 - val_loss: 2.9171 - val_acc: 0.6097\n",
      "Epoch 25/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0541 - acc: 0.9893 - val_loss: 3.3503 - val_acc: 0.6135\n",
      "Epoch 26/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0576 - acc: 0.9887 - val_loss: 3.3959 - val_acc: 0.6183\n",
      "Epoch 27/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.1294 - acc: 0.9694 - val_loss: 2.5086 - val_acc: 0.6096\n",
      "Epoch 28/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0793 - acc: 0.9829 - val_loss: 3.1539 - val_acc: 0.6193\n",
      "Epoch 29/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3944 - acc: 0.5311 - val_loss: 1.4620 - val_acc: 0.5397\n",
      "Epoch 30/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.7707 - acc: 0.7552 - val_loss: 1.8098 - val_acc: 0.5983\n",
      "Epoch 31/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.2451 - acc: 0.9300 - val_loss: 2.3099 - val_acc: 0.6128\n",
      "Epoch 32/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.1932 - acc: 0.9502 - val_loss: 1.9159 - val_acc: 0.5813\n",
      "Epoch 33/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.1617 - acc: 0.9538 - val_loss: 2.7059 - val_acc: 0.6137\n",
      "Epoch 34/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0401 - acc: 0.9901 - val_loss: 3.1192 - val_acc: 0.6184\n",
      "Epoch 35/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0254 - acc: 0.9952 - val_loss: 3.2384 - val_acc: 0.6128\n",
      "Epoch 36/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0342 - acc: 0.9921 - val_loss: 3.5569 - val_acc: 0.6170\n",
      "Epoch 37/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0205 - acc: 0.9960 - val_loss: 3.5791 - val_acc: 0.6197\n",
      "Epoch 38/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0159 - acc: 0.9974 - val_loss: 3.7251 - val_acc: 0.6183\n",
      "Epoch 39/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0165 - acc: 0.9970 - val_loss: 3.7657 - val_acc: 0.6179\n",
      "Epoch 40/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0153 - acc: 0.9975 - val_loss: 3.9680 - val_acc: 0.6127\n",
      "Epoch 41/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0737 - acc: 0.9830 - val_loss: 2.9669 - val_acc: 0.6102\n",
      "Epoch 42/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0826 - acc: 0.9839 - val_loss: 3.5937 - val_acc: 0.6054\n",
      "Epoch 43/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0389 - acc: 0.9933 - val_loss: 3.6189 - val_acc: 0.6115\n",
      "Epoch 44/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.1076 - acc: 0.9757 - val_loss: 3.0050 - val_acc: 0.6109\n",
      "Epoch 45/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0464 - acc: 0.9918 - val_loss: 3.4345 - val_acc: 0.6208\n",
      "Epoch 46/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0365 - acc: 0.9944 - val_loss: 3.5029 - val_acc: 0.6172\n",
      "Epoch 47/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0416 - acc: 0.9944 - val_loss: 3.6008 - val_acc: 0.6135\n",
      "Epoch 48/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0531 - acc: 0.9912 - val_loss: 3.5073 - val_acc: 0.6192\n",
      "Epoch 49/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.1065 - acc: 0.9776 - val_loss: 2.8435 - val_acc: 0.6160\n",
      "Epoch 50/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0728 - acc: 0.9820 - val_loss: 2.9962 - val_acc: 0.6057\n",
      "Epoch 51/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0321 - acc: 0.9934 - val_loss: 3.4181 - val_acc: 0.6185\n",
      "Epoch 52/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0215 - acc: 0.9963 - val_loss: 3.6895 - val_acc: 0.6104\n",
      "Epoch 53/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0387 - acc: 0.9927 - val_loss: 3.4413 - val_acc: 0.6088\n",
      "Epoch 54/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0456 - acc: 0.9917 - val_loss: 3.5054 - val_acc: 0.6126\n",
      "Epoch 55/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0840 - acc: 0.9835 - val_loss: 3.3254 - val_acc: 0.6044\n",
      "Epoch 56/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0501 - acc: 0.9899 - val_loss: 3.5586 - val_acc: 0.6014\n",
      "Epoch 57/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0421 - acc: 0.9931 - val_loss: 3.5371 - val_acc: 0.6136\n",
      "Epoch 58/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0543 - acc: 0.9923 - val_loss: 3.5581 - val_acc: 0.6131\n",
      "Epoch 59/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.3424 - acc: 0.9149 - val_loss: 2.7975 - val_acc: 0.6102\n",
      "Epoch 60/92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.0626 - acc: 0.9889 - val_loss: 3.2843 - val_acc: 0.6201\n",
      "Epoch 61/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0371 - acc: 0.9943 - val_loss: 3.5157 - val_acc: 0.6100\n",
      "Epoch 62/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0416 - acc: 0.9933 - val_loss: 3.4504 - val_acc: 0.6239\n",
      "Epoch 63/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0311 - acc: 0.9953 - val_loss: 3.7355 - val_acc: 0.6195\n",
      "Epoch 64/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0269 - acc: 0.9954 - val_loss: 3.7134 - val_acc: 0.6138\n",
      "Epoch 65/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0452 - acc: 0.9934 - val_loss: 3.6916 - val_acc: 0.6136\n",
      "Epoch 66/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.2144 - acc: 0.9505 - val_loss: 2.7005 - val_acc: 0.6098\n",
      "Epoch 67/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0454 - acc: 0.9899 - val_loss: 3.2319 - val_acc: 0.6216\n",
      "Epoch 68/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0179 - acc: 0.9973 - val_loss: 3.6546 - val_acc: 0.6160\n",
      "Epoch 69/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0284 - acc: 0.9948 - val_loss: 3.5785 - val_acc: 0.6173\n",
      "Epoch 70/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0394 - acc: 0.9921 - val_loss: 3.4083 - val_acc: 0.6131\n",
      "Epoch 71/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0395 - acc: 0.9928 - val_loss: 3.5002 - val_acc: 0.6070\n",
      "Epoch 72/92\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.0887 - acc: 0.9806 - val_loss: 3.6419 - val_acc: 0.6021\n",
      "Epoch 73/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0695 - acc: 0.9865 - val_loss: 3.3167 - val_acc: 0.6101\n",
      "Epoch 74/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0452 - acc: 0.9919 - val_loss: 3.4523 - val_acc: 0.6149\n",
      "Epoch 75/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0326 - acc: 0.9962 - val_loss: 3.9431 - val_acc: 0.6157\n",
      "Epoch 76/92\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.0784 - acc: 0.9854 - val_loss: 3.1921 - val_acc: 0.6099\n",
      "Epoch 77/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.1140 - acc: 0.9771 - val_loss: 2.3532 - val_acc: 0.5933\n",
      "Epoch 78/92\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 0.0569 - acc: 0.9886 - val_loss: 3.3398 - val_acc: 0.6137\n",
      "Epoch 79/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0595 - acc: 0.9907 - val_loss: 3.5671 - val_acc: 0.6116\n",
      "Epoch 80/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.4527 - acc: 0.8902 - val_loss: 2.6286 - val_acc: 0.5979\n",
      "Epoch 81/92\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.0565 - acc: 0.9878 - val_loss: 3.1402 - val_acc: 0.6144\n",
      "Epoch 82/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0355 - acc: 0.9957 - val_loss: 3.5854 - val_acc: 0.6176\n",
      "Epoch 83/92\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 0.0507 - acc: 0.9943 - val_loss: 3.7019 - val_acc: 0.6174\n",
      "Epoch 84/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0441 - acc: 0.9965 - val_loss: 3.8909 - val_acc: 0.6150\n",
      "Epoch 85/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0476 - acc: 0.9920 - val_loss: 3.4750 - val_acc: 0.6135\n",
      "Epoch 86/92\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.0342 - acc: 0.9943 - val_loss: 3.5995 - val_acc: 0.6139\n",
      "Epoch 87/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0257 - acc: 0.9965 - val_loss: 3.7227 - val_acc: 0.6126\n",
      "Epoch 88/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0367 - acc: 0.9951 - val_loss: 3.6736 - val_acc: 0.6099\n",
      "Epoch 89/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0383 - acc: 0.9949 - val_loss: 3.6830 - val_acc: 0.6120\n",
      "Epoch 90/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0470 - acc: 0.9933 - val_loss: 3.6405 - val_acc: 0.6064\n",
      "Epoch 91/92\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 0.0539 - acc: 0.9920 - val_loss: 3.7224 - val_acc: 0.6088\n",
      "Epoch 92/92\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 0.0530 - acc: 0.9937 - val_loss: 3.4811 - val_acc: 0.6110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8dfe948b00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "my_model.fit(train_images, train_y,\n",
    "             initial_epoch=epoch_start,\n",
    "             epochs=92,\n",
    "             batch_size=256,\n",
    "             shuffle=True,\n",
    "             validation_data=(cv_images, cv_y),\n",
    "             callbacks=[TensorBoard(log_dir='tb')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 61.1%\n"
     ]
    }
   ],
   "source": [
    "# score = my_model.evaluate(cv_images, cv_y, verbose=1)\n",
    "print('Test accuracy: {}%'.format(100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, AlexNet does not work very well on such a small dataset. Recall what you have learned from this class to improve its performance. You can also take a look at the [Dropout technique](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) and its [implementation in Keras](https://keras.io/layers/core/#dropout). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 48)        1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 128)       153728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 192)         221376    \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 8, 128)         221312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 9,342,922\n",
      "Trainable params: 9,342,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def create_conv_net():\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "\n",
    "    x = Conv2D(48, (3, 3), strides=(1,1), padding='same', activation='relu')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, (5, 5),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(192, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3),  strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input_img, output, name=\"classifier\")\n",
    "    return model\n",
    "\n",
    "my_model = create_conv_net()\n",
    "my_model.summary()\n",
    "plot_model(my_model, to_file='my_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "44800/50000 [=========================>....] - ETA: 0s - loss: 14.4915 - acc: 0.1009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ac3e2c937070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m              validation_data=(cv_images, cv_y))\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py37/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "my_model.fit(train_images, train_y,\n",
    "             epochs=50,\n",
    "             batch_size=256,\n",
    "             shuffle=True,\n",
    "             validation_data=(cv_images, cv_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
